## William Sivutha Poch 5938122 
# Big data project 1

### Download facebook dataset


```python
! wget https://download.data.world/s/etiswtd7xih7fxhsvsgdxm6bxmznfj -O abc.csv
! wget https://download.data.world/s/c54sbdqkgro5w6w2tuhyfn5kwusztv -O bbc.csv
! wget https://download.data.world/s/at7oomaccb2sr7b3l46hl7oe5eh3w2 -O cbs.csv
! wget https://download.data.world/s/jxwxasqakdeitce45tgmvk54yliwos -O cnn.csv
! wget https://download.data.world/s/s7367nitc57qq3zpif32dju26tzj4w -O foxfriends.csv
! wget https://download.data.world/s/r3vz63lumdk652wtlo23np332z77av -O foxnews.csv
! wget https://download.data.world/s/uemffyw6qnwrzyi3my3uqn46dpyfpm -O nbc.csv
! wget https://download.data.world/s/3sjhaah6yajvxznnr3pegibm2mavns -O la.csv
! wget https://download.data.world/s/p5p7shwkl4iscqy7z32fj3y4k4cbur -O npr.csv

```

    --2020-04-13 03:00:10--  https://download.data.world/s/etiswtd7xih7fxhsvsgdxm6bxmznfj
    Resolving download.data.world (download.data.world)... 107.23.216.235, 35.169.251.217, 18.233.130.49
    Connecting to download.data.world (download.data.world)|107.23.216.235|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/b76da15a-5b14-4511-a08b-b8fabc27d60b/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1MjQxLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiJiMjBhOTViYTEwMWVlY2ZmNGE2Y2YxNzdlZjg0YWM1Y2EyZWVjZWQ0In0.FB4xiWCGX4HzR7QxR4fBEfwAhhB9t4-whRrSiymWBzYrJ3S4EbcTbqqkK9QL7P8k_7cAOnpt1SLNExp_3KjChA [following]
    --2020-04-13 03:00:10--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/b76da15a-5b14-4511-a08b-b8fabc27d60b/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1MjQxLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiJiMjBhOTViYTEwMWVlY2ZmNGE2Y2YxNzdlZjg0YWM1Y2EyZWVjZWQ0In0.FB4xiWCGX4HzR7QxR4fBEfwAhhB9t4-whRrSiymWBzYrJ3S4EbcTbqqkK9QL7P8k_7cAOnpt1SLNExp_3KjChA
    Resolving query.data.world (query.data.world)... 107.23.216.235, 35.169.251.217, 18.233.130.49
    Connecting to query.data.world (query.data.world)|107.23.216.235|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜abc.csvâ€™
    
    abc.csv                 [             <=>    ]  24.52M  7.67MB/s    in 3.2s    
    
    2020-04-13 03:00:14 (7.67 MB/s) - â€˜abc.csvâ€™ saved [25715035]
    
    --2020-04-13 03:00:14--  https://download.data.world/s/c54sbdqkgro5w6w2tuhyfn5kwusztv
    Resolving download.data.world (download.data.world)... 35.169.251.217, 107.23.216.235, 18.233.130.49
    Connecting to download.data.world (download.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/d7101104-1616-41db-adcd-611169b12ede/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1MzYxLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiIxMTFiNGY2OTYxYjczMWMyOGM5Y2YwZGViYTM1N2MwZjgxODFmNjBiIn0.Nvxs0NH1gP29H7NlftTabC2c_z2n4Uv_yJkgxOfunCCJ3RtRnspgocE9ES6erzlVyhO8f5S7uQE-5o0WjxzCmw [following]
    --2020-04-13 03:00:14--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/d7101104-1616-41db-adcd-611169b12ede/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1MzYxLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiIxMTFiNGY2OTYxYjczMWMyOGM5Y2YwZGViYTM1N2MwZjgxODFmNjBiIn0.Nvxs0NH1gP29H7NlftTabC2c_z2n4Uv_yJkgxOfunCCJ3RtRnspgocE9ES6erzlVyhO8f5S7uQE-5o0WjxzCmw
    Resolving query.data.world (query.data.world)... 107.23.216.235, 18.233.130.49, 35.169.251.217
    Connecting to query.data.world (query.data.world)|107.23.216.235|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜bbc.csvâ€™
    
    bbc.csv                 [      <=>           ]  10.39M  7.57MB/s    in 1.4s    
    
    2020-04-13 03:00:17 (7.57 MB/s) - â€˜bbc.csvâ€™ saved [10898457]
    
    --2020-04-13 03:00:17--  https://download.data.world/s/at7oomaccb2sr7b3l46hl7oe5eh3w2
    Resolving download.data.world (download.data.world)... 18.233.130.49, 107.23.216.235, 35.169.251.217
    Connecting to download.data.world (download.data.world)|18.233.130.49|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/5d213273-6cba-4448-8b97-858e9f47a5dd/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NDM3LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiJiNjJhNWE1Mzk4MGE5ZTgzNjBmZjRkZTNjZDY1Zjk0MWQ3NTE1YjQ2In0.Yci13ZCkOD9B9QWNkXtKiaQQz8rGODJJi8BG1-7kr8MTbTO9JlqszXAmdamYcUoL6y4asNHSN5nRdxfah8kCLA [following]
    --2020-04-13 03:00:17--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/5d213273-6cba-4448-8b97-858e9f47a5dd/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NDM3LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiJiNjJhNWE1Mzk4MGE5ZTgzNjBmZjRkZTNjZDY1Zjk0MWQ3NTE1YjQ2In0.Yci13ZCkOD9B9QWNkXtKiaQQz8rGODJJi8BG1-7kr8MTbTO9JlqszXAmdamYcUoL6y4asNHSN5nRdxfah8kCLA
    Resolving query.data.world (query.data.world)... 35.169.251.217, 18.233.130.49, 107.23.216.235
    Connecting to query.data.world (query.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜cbs.csvâ€™
    
    cbs.csv                 [            <=>     ]  23.34M  8.07MB/s    in 2.9s    
    
    2020-04-13 03:00:21 (8.07 MB/s) - â€˜cbs.csvâ€™ saved [24471499]
    
    --2020-04-13 03:00:21--  https://download.data.world/s/jxwxasqakdeitce45tgmvk54yliwos
    Resolving download.data.world (download.data.world)... 35.169.251.217, 18.233.130.49, 107.23.216.235
    Connecting to download.data.world (download.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/2fb790cd-05b3-4763-8ffd-321d9cae7c37/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NDY5LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiI1OGNmZGQzM2Y1OGQ1YTdmZGFkZWJiNjAyNWU0NmQ0NzE2MjUxNmRjIn0.yX6OB4r8yLwt62IAO7lxz2EPDj5xY-fs-RWBd_BuhTIMcv2FgH_k71NK-i-gl8Ez_ha2kVFjCodM1yw1PClUNA [following]
    --2020-04-13 03:00:21--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/2fb790cd-05b3-4763-8ffd-321d9cae7c37/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NDY5LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiI1OGNmZGQzM2Y1OGQ1YTdmZGFkZWJiNjAyNWU0NmQ0NzE2MjUxNmRjIn0.yX6OB4r8yLwt62IAO7lxz2EPDj5xY-fs-RWBd_BuhTIMcv2FgH_k71NK-i-gl8Ez_ha2kVFjCodM1yw1PClUNA
    Resolving query.data.world (query.data.world)... 107.23.216.235, 35.169.251.217, 18.233.130.49
    Connecting to query.data.world (query.data.world)|107.23.216.235|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜cnn.csvâ€™
    
    cnn.csv                 [         <=>        ]  17.78M  7.82MB/s    in 2.3s    
    
    2020-04-13 03:00:24 (7.82 MB/s) - â€˜cnn.csvâ€™ saved [18647650]
    
    --2020-04-13 03:00:24--  https://download.data.world/s/s7367nitc57qq3zpif32dju26tzj4w
    Resolving download.data.world (download.data.world)... 107.23.216.235, 18.233.130.49, 35.169.251.217
    Connecting to download.data.world (download.data.world)|107.23.216.235|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/c105ae78-25da-4c7e-aa89-8375a120947e/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NDk3LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiI2ZjRmMGE0YzRjN2UxNTY4ZWMwZjI2YmI5OTJjNDlhZTYyNGE5OTAzIn0.jz2BBDH-hGCdLFjfEa8Ivc0xX6iQ40I5ZB0ZWWLpb1qbvg_TmwDTb22WPQi3NrebgeeLpKjAe8C53WDbGfYLow [following]
    --2020-04-13 03:00:25--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/c105ae78-25da-4c7e-aa89-8375a120947e/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NDk3LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiI2ZjRmMGE0YzRjN2UxNTY4ZWMwZjI2YmI5OTJjNDlhZTYyNGE5OTAzIn0.jz2BBDH-hGCdLFjfEa8Ivc0xX6iQ40I5ZB0ZWWLpb1qbvg_TmwDTb22WPQi3NrebgeeLpKjAe8C53WDbGfYLow
    Resolving query.data.world (query.data.world)... 35.169.251.217, 18.233.130.49, 107.23.216.235
    Connecting to query.data.world (query.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜foxfriends.csvâ€™
    
    foxfriends.csv          [  <=>               ]   3.08M  11.2MB/s    in 0.3s    
    
    2020-04-13 03:00:26 (11.2 MB/s) - â€˜foxfriends.csvâ€™ saved [3229054]
    
    --2020-04-13 03:00:26--  https://download.data.world/s/r3vz63lumdk652wtlo23np332z77av
    Resolving download.data.world (download.data.world)... 35.169.251.217, 18.233.130.49, 107.23.216.235
    Connecting to download.data.world (download.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/ad249a75-dd40-4909-8619-8a5e1b08f488/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NTMzLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiI1ODZhMzMxNWVmNzVkOWFkODUwYTI5YzUwYmQ1NmY1ZDNkYWUwOGY1In0.2uG1K73LOhmyPoP9xwvkIvjEmRx_OwZbhgj5K3GmtkOIHKrqe-KyR_gcQGTxiPshRiTyzw5IZErXT6PpbCStpg [following]
    --2020-04-13 03:00:26--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/ad249a75-dd40-4909-8619-8a5e1b08f488/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NTMzLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiI1ODZhMzMxNWVmNzVkOWFkODUwYTI5YzUwYmQ1NmY1ZDNkYWUwOGY1In0.2uG1K73LOhmyPoP9xwvkIvjEmRx_OwZbhgj5K3GmtkOIHKrqe-KyR_gcQGTxiPshRiTyzw5IZErXT6PpbCStpg
    Resolving query.data.world (query.data.world)... 35.169.251.217, 18.233.130.49, 107.23.216.235
    Connecting to query.data.world (query.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜foxnews.csvâ€™
    
    foxnews.csv             [          <=>       ]  19.97M  8.28MB/s    in 2.4s    
    
    2020-04-13 03:00:29 (8.28 MB/s) - â€˜foxnews.csvâ€™ saved [20942622]
    
    --2020-04-13 03:00:30--  https://download.data.world/s/uemffyw6qnwrzyi3my3uqn46dpyfpm
    Resolving download.data.world (download.data.world)... 18.233.130.49, 107.23.216.235, 35.169.251.217
    Connecting to download.data.world (download.data.world)|18.233.130.49|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/cbaaca1d-2a68-4ab1-bf42-eb65b875c428/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NTcxLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiI5OWM0MmE2ZTQyYjI3ZTM3MjkyMzQ0OWYzZGQ2N2YxNmFlYzJhNGUzIn0.Q-SCwuYeXqJ8cXkKobF2qosX5Nl-_Vx5l86Sq63WpHt1x6LW7dgLdS3QvPJTUjYwc6hKSHFXTb-hBHB7ESGsDQ [following]
    --2020-04-13 03:00:30--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/cbaaca1d-2a68-4ab1-bf42-eb65b875c428/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1NTcxLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiI5OWM0MmE2ZTQyYjI3ZTM3MjkyMzQ0OWYzZGQ2N2YxNmFlYzJhNGUzIn0.Q-SCwuYeXqJ8cXkKobF2qosX5Nl-_Vx5l86Sq63WpHt1x6LW7dgLdS3QvPJTUjYwc6hKSHFXTb-hBHB7ESGsDQ
    Resolving query.data.world (query.data.world)... 35.169.251.217, 18.233.130.49, 107.23.216.235
    Connecting to query.data.world (query.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜nbc.csvâ€™
    
    nbc.csv                 [              <=>   ]  28.20M  8.01MB/s    in 3.5s    
    
    2020-04-13 03:00:34 (8.01 MB/s) - â€˜nbc.csvâ€™ saved [29574015]
    
    --2020-04-13 03:00:34--  https://download.data.world/s/3sjhaah6yajvxznnr3pegibm2mavns
    Resolving download.data.world (download.data.world)... 35.169.251.217, 107.23.216.235, 18.233.130.49
    Connecting to download.data.world (download.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/4cc89238-ea4c-4c4b-8c83-376725b4c232/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1OTEwLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiIzM2FkZjE4MTA3NDliNDUyMDY1Njg2NGYxZTJkMDBmNzU1M2MzNjY5In0.yHsriAdXcDxPXSxIT2JbcIlphVwCF66nVgmAKKIMaqGhx16BHuNbz0_oaEmrvDiOU8rt5BeG3x-EXV6BVS5Lzg [following]
    --2020-04-13 03:00:34--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/4cc89238-ea4c-4c4b-8c83-376725b4c232/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1OTEwLCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiIzM2FkZjE4MTA3NDliNDUyMDY1Njg2NGYxZTJkMDBmNzU1M2MzNjY5In0.yHsriAdXcDxPXSxIT2JbcIlphVwCF66nVgmAKKIMaqGhx16BHuNbz0_oaEmrvDiOU8rt5BeG3x-EXV6BVS5Lzg
    Resolving query.data.world (query.data.world)... 107.23.216.235, 35.169.251.217, 18.233.130.49
    Connecting to query.data.world (query.data.world)|107.23.216.235|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜la.csvâ€™
    
    la.csv                  [           <=>      ]  21.27M  8.36MB/s    in 2.5s    
    
    2020-04-13 03:00:38 (8.36 MB/s) - â€˜la.csvâ€™ saved [22303147]
    
    --2020-04-13 03:00:38--  https://download.data.world/s/p5p7shwkl4iscqy7z32fj3y4k4cbur
    Resolving download.data.world (download.data.world)... 35.169.251.217, 18.233.130.49, 107.23.216.235
    Connecting to download.data.world (download.data.world)|35.169.251.217|:443... connected.
    HTTP request sent, awaiting response... 301 Moved Permanently
    Location: https://query.data.world/queries/martinchek/2012-2016-facebook-posts/64e2e53a-1ab0-477e-9361-ae72a7b70c5d/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1OTM5LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiJiZDgwMjgxNmQ3MzJjM2Y0ZDc1NGE2N2IzNzJmZWExZGVmOWM4YTAyIn0.OXvZDe18ivD-wEDu783OcKR4gnQ4DkZqzwxdisMnxwVU1XulDgydCA2iOVY8u4rfYdiRAJB8qVk02qGDW4Bv9g [following]
    --2020-04-13 03:00:38--  https://query.data.world/queries/martinchek/2012-2016-facebook-posts/64e2e53a-1ab0-477e-9361-ae72a7b70c5d/result_download?parameters&fileName=query_results&mimetype=text%2Fcsv&auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OmdhcnJvcyIsImlzcyI6ImFnZW50OmdhcnJvczo6ZTMzZGU4YTAtMTVhMC00OTYyLWEyOGQtYmE0ZTJkN2I3ZmRmIiwiaWF0IjoxNTg2NTk1OTM5LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiJiZDgwMjgxNmQ3MzJjM2Y0ZDc1NGE2N2IzNzJmZWExZGVmOWM4YTAyIn0.OXvZDe18ivD-wEDu783OcKR4gnQ4DkZqzwxdisMnxwVU1XulDgydCA2iOVY8u4rfYdiRAJB8qVk02qGDW4Bv9g
    Resolving query.data.world (query.data.world)... 18.233.130.49, 107.23.216.235, 35.169.251.217
    Connecting to query.data.world (query.data.world)|18.233.130.49|:443... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: unspecified [text/csv]
    Saving to: â€˜npr.csvâ€™
    
    npr.csv                 [               <=>  ]  29.31M  8.84MB/s    in 3.3s    
    
    2020-04-13 03:00:43 (8.84 MB/s) - â€˜npr.csvâ€™ saved [30733654]
    



```python
# View the files
! ls -l *.csv
```

    -rw-r--r-- 1 root root 25715035 Apr 13 03:00 abc.csv
    -rw-r--r-- 1 root root 10898457 Apr 13 03:00 bbc.csv
    -rw-r--r-- 1 root root 24471499 Apr 13 03:00 cbs.csv
    -rw-r--r-- 1 root root 18647650 Apr 13 03:00 cnn.csv
    -rw-r--r-- 1 root root  3229054 Apr 13 03:00 foxfriends.csv
    -rw-r--r-- 1 root root 20942622 Apr 13 03:00 foxnews.csv
    -rw-r--r-- 1 root root 22303147 Apr 13 03:00 la.csv
    -rw-r--r-- 1 root root 29574015 Apr 13 03:00 nbc.csv
    -rw-r--r-- 1 root root 30733654 Apr 13 03:00 npr.csv


## Copy csv files from local to the HDFS


```python
! hdfs dfs -put abc.csv 
! hdfs dfs -put bbc.csv
! hdfs dfs -put cbs.csv
! hdfs dfs -put cnn.csv
! hdfs dfs -put foxfriends.csv
! hdfs dfs -put foxnews.csv
! hdfs dfs -put nbc.csv
! hdfs dfs -put la.csv
! hdfs dfs -put npr.csv
```

    put: `abc.csv': File exists
    put: `bbc.csv': File exists
    put: `cbs.csv': File exists
    put: `cnn.csv': File exists
    put: `foxfriends.csv': File exists
    put: `foxnews.csv': File exists
    put: `nbc.csv': File exists
    put: `la.csv': File exists
    put: `npr.csv': File exists



```python
# View the files in hdfs
! hdfs dfs -ls ./
```

    Found 10 items
    drwxr-xr-x   - root hadoop          0 2020-04-13 03:00 .sparkStaging
    -rw-r--r--   2 root hadoop   25715035 2020-04-11 15:36 abc.csv
    -rw-r--r--   2 root hadoop   10898457 2020-04-11 15:36 bbc.csv
    -rw-r--r--   2 root hadoop   24471499 2020-04-11 15:36 cbs.csv
    -rw-r--r--   2 root hadoop   18647650 2020-04-11 15:58 cnn.csv
    -rw-r--r--   2 root hadoop    3229054 2020-04-11 15:36 foxfriends.csv
    -rw-r--r--   2 root hadoop   20942622 2020-04-11 15:36 foxnews.csv
    -rw-r--r--   2 root hadoop   22303147 2020-04-11 15:36 la.csv
    -rw-r--r--   2 root hadoop   29574015 2020-04-11 15:36 nbc.csv
    -rw-r--r--   2 root hadoop   30733654 2020-04-11 15:37 npr.csv


## Read all csv files and remove headers from them


```python
rdd1 = sc.textFile('npr.csv').cache()
rdd2 = sc.textFile('abc.csv').cache()
rdd3 = sc.textFile('cbs.csv').cache()
rdd4 = sc.textFile('cnn.csv').cache()
rdd5 = sc.textFile('foxfriends.csv').cache()
rdd6 = sc.textFile('foxnews.csv').cache()
rdd7 = sc.textFile('la.csv').cache()
rdd8 = sc.textFile('nbc.csv').cache()
rdd9 = sc.textFile('bbc.csv').cache()

# Function to remove the header.
def remove_header(x):
    header = x.first()
    return x.filter(lambda row: row != header)

rdd1 = remove_header(rdd1)
rdd2 = remove_header(rdd2)
rdd3 = remove_header(rdd3)
rdd4 = remove_header(rdd4)
rdd5 = remove_header(rdd5)
rdd6 = remove_header(rdd6)
rdd7 = remove_header(rdd7)
rdd8 = remove_header(rdd8)
rdd9 = remove_header(rdd9)
```

## Merge all into one RDD


```python
data = sc.union([rdd1, rdd2, rdd3, rdd4, rdd5, rdd6, rdd7, rdd8, rdd9])
data.take(2)
```




    ['"\ufeff""10643211755_255251391226420""",10643211755,From KPLU: Why most people get divorced in March,NULL,Divorce is a nasty business and this time of the year business is booming. KPLU looks at the reasons divorce filings peak in March every year.,kplu.org,link,shared_story,538,244,525,0,0,0,0,0,0,http://www.kplu.org/post/why-most-people-get-divorced-march,https://external.xx.fbcdn.net/safe_image.php?d=AQDfZ4ruY3ZHcwTr&w=130&h=130&url=http%3A%2F%2Fmediad.publicbroadcasting.net%2Fp%2Fkplu%2Ffiles%2Fdivorce_sign.jpg&cfs=1,2012-03-07T12:50:24',
     '"\ufeff""10643211755_388881894474609""",10643211755,"How Do You Ship A Horse To The London Olympics? Carefully, And Via FedEx",NULL,"The elite athletes who travel to London for this summer\'s Olympic Games will include petite gymnasts, huge wrestlers â€” and elite horses, which compete in dressage and other events. The man whose job it is to get 50-60 horses to England says, \'It\'s quite a logistical feat.\'",npr.org,link,shared_story,1507,132,1349,0,0,0,0,0,0,http://www.npr.org/blogs/thetwo-way/2012/03/07/148085883/how-do-you-ship-a-horse-to-the-2012-london-olympics,https://external.xx.fbcdn.net/safe_image.php?d=AQD4TqJbDUQAGoNZ&w=130&h=130&url=http%3A%2F%2Fmedia.npr.org%2Fassets%2Fimg%2F2012%2F03%2F06%2Fhorse_olympics_custom.jpg%3Ft%3D1331078523&cfs=1,2012-03-07T14:17:24']



### Download NLTK for natural language processing


```python
# Download and install nltk
!pip install cython nltk
import nltk 
nltk.download('all')
!pip install --upgrade nltk
```

    Requirement already satisfied: cython in /opt/conda/lib/python3.7/site-packages (0.29.16)
    Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.4.5)
    Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk) (1.12.0)


    [nltk_data] Downloading collection 'all'
    [nltk_data]    | 
    [nltk_data]    | Downloading package abc to /root/nltk_data...
    [nltk_data]    |   Package abc is already up-to-date!
    [nltk_data]    | Downloading package alpino to /root/nltk_data...
    [nltk_data]    |   Package alpino is already up-to-date!
    [nltk_data]    | Downloading package biocreative_ppi to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package biocreative_ppi is already up-to-date!
    [nltk_data]    | Downloading package brown to /root/nltk_data...
    [nltk_data]    |   Package brown is already up-to-date!
    [nltk_data]    | Downloading package brown_tei to /root/nltk_data...
    [nltk_data]    |   Package brown_tei is already up-to-date!
    [nltk_data]    | Downloading package cess_cat to /root/nltk_data...
    [nltk_data]    |   Package cess_cat is already up-to-date!
    [nltk_data]    | Downloading package cess_esp to /root/nltk_data...
    [nltk_data]    |   Package cess_esp is already up-to-date!
    [nltk_data]    | Downloading package chat80 to /root/nltk_data...
    [nltk_data]    |   Package chat80 is already up-to-date!
    [nltk_data]    | Downloading package city_database to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package city_database is already up-to-date!
    [nltk_data]    | Downloading package cmudict to /root/nltk_data...
    [nltk_data]    |   Package cmudict is already up-to-date!
    [nltk_data]    | Downloading package comparative_sentences to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package comparative_sentences is already up-to-
    [nltk_data]    |       date!
    [nltk_data]    | Downloading package comtrans to /root/nltk_data...
    [nltk_data]    |   Package comtrans is already up-to-date!
    [nltk_data]    | Downloading package conll2000 to /root/nltk_data...
    [nltk_data]    |   Package conll2000 is already up-to-date!
    [nltk_data]    | Downloading package conll2002 to /root/nltk_data...
    [nltk_data]    |   Package conll2002 is already up-to-date!
    [nltk_data]    | Downloading package conll2007 to /root/nltk_data...
    [nltk_data]    |   Package conll2007 is already up-to-date!
    [nltk_data]    | Downloading package crubadan to /root/nltk_data...
    [nltk_data]    |   Package crubadan is already up-to-date!
    [nltk_data]    | Downloading package dependency_treebank to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package dependency_treebank is already up-to-date!
    [nltk_data]    | Downloading package dolch to /root/nltk_data...
    [nltk_data]    |   Package dolch is already up-to-date!
    [nltk_data]    | Downloading package europarl_raw to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package europarl_raw is already up-to-date!
    [nltk_data]    | Downloading package floresta to /root/nltk_data...
    [nltk_data]    |   Package floresta is already up-to-date!
    [nltk_data]    | Downloading package framenet_v15 to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package framenet_v15 is already up-to-date!
    [nltk_data]    | Downloading package framenet_v17 to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package framenet_v17 is already up-to-date!
    [nltk_data]    | Downloading package gazetteers to /root/nltk_data...
    [nltk_data]    |   Package gazetteers is already up-to-date!
    [nltk_data]    | Downloading package genesis to /root/nltk_data...
    [nltk_data]    |   Package genesis is already up-to-date!
    [nltk_data]    | Downloading package gutenberg to /root/nltk_data...
    [nltk_data]    |   Package gutenberg is already up-to-date!
    [nltk_data]    | Downloading package ieer to /root/nltk_data...
    [nltk_data]    |   Package ieer is already up-to-date!
    [nltk_data]    | Downloading package inaugural to /root/nltk_data...
    [nltk_data]    |   Package inaugural is already up-to-date!
    [nltk_data]    | Downloading package indian to /root/nltk_data...
    [nltk_data]    |   Package indian is already up-to-date!
    [nltk_data]    | Downloading package jeita to /root/nltk_data...
    [nltk_data]    |   Package jeita is already up-to-date!
    [nltk_data]    | Downloading package kimmo to /root/nltk_data...
    [nltk_data]    |   Package kimmo is already up-to-date!
    [nltk_data]    | Downloading package knbc to /root/nltk_data...
    [nltk_data]    |   Package knbc is already up-to-date!
    [nltk_data]    | Downloading package lin_thesaurus to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package lin_thesaurus is already up-to-date!
    [nltk_data]    | Downloading package mac_morpho to /root/nltk_data...
    [nltk_data]    |   Package mac_morpho is already up-to-date!
    [nltk_data]    | Downloading package machado to /root/nltk_data...
    [nltk_data]    |   Package machado is already up-to-date!
    [nltk_data]    | Downloading package masc_tagged to /root/nltk_data...
    [nltk_data]    |   Package masc_tagged is already up-to-date!
    [nltk_data]    | Downloading package moses_sample to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package moses_sample is already up-to-date!
    [nltk_data]    | Downloading package movie_reviews to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package movie_reviews is already up-to-date!
    [nltk_data]    | Downloading package names to /root/nltk_data...
    [nltk_data]    |   Package names is already up-to-date!
    [nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...
    [nltk_data]    |   Package nombank.1.0 is already up-to-date!
    [nltk_data]    | Downloading package nps_chat to /root/nltk_data...
    [nltk_data]    |   Package nps_chat is already up-to-date!
    [nltk_data]    | Downloading package omw to /root/nltk_data...
    [nltk_data]    |   Package omw is already up-to-date!
    [nltk_data]    | Downloading package opinion_lexicon to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package opinion_lexicon is already up-to-date!
    [nltk_data]    | Downloading package paradigms to /root/nltk_data...
    [nltk_data]    |   Package paradigms is already up-to-date!
    [nltk_data]    | Downloading package pil to /root/nltk_data...
    [nltk_data]    |   Package pil is already up-to-date!
    [nltk_data]    | Downloading package pl196x to /root/nltk_data...
    [nltk_data]    |   Package pl196x is already up-to-date!
    [nltk_data]    | Downloading package ppattach to /root/nltk_data...
    [nltk_data]    |   Package ppattach is already up-to-date!
    [nltk_data]    | Downloading package problem_reports to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package problem_reports is already up-to-date!
    [nltk_data]    | Downloading package propbank to /root/nltk_data...
    [nltk_data]    |   Package propbank is already up-to-date!
    [nltk_data]    | Downloading package ptb to /root/nltk_data...
    [nltk_data]    |   Package ptb is already up-to-date!
    [nltk_data]    | Downloading package product_reviews_1 to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package product_reviews_1 is already up-to-date!
    [nltk_data]    | Downloading package product_reviews_2 to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package product_reviews_2 is already up-to-date!
    [nltk_data]    | Downloading package pros_cons to /root/nltk_data...
    [nltk_data]    |   Package pros_cons is already up-to-date!
    [nltk_data]    | Downloading package qc to /root/nltk_data...
    [nltk_data]    |   Package qc is already up-to-date!
    [nltk_data]    | Downloading package reuters to /root/nltk_data...
    [nltk_data]    |   Package reuters is already up-to-date!
    [nltk_data]    | Downloading package rte to /root/nltk_data...
    [nltk_data]    |   Package rte is already up-to-date!
    [nltk_data]    | Downloading package semcor to /root/nltk_data...
    [nltk_data]    |   Package semcor is already up-to-date!
    [nltk_data]    | Downloading package senseval to /root/nltk_data...
    [nltk_data]    |   Package senseval is already up-to-date!
    [nltk_data]    | Downloading package sentiwordnet to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package sentiwordnet is already up-to-date!
    [nltk_data]    | Downloading package sentence_polarity to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package sentence_polarity is already up-to-date!
    [nltk_data]    | Downloading package shakespeare to /root/nltk_data...
    [nltk_data]    |   Package shakespeare is already up-to-date!
    [nltk_data]    | Downloading package sinica_treebank to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package sinica_treebank is already up-to-date!
    [nltk_data]    | Downloading package smultron to /root/nltk_data...
    [nltk_data]    |   Package smultron is already up-to-date!
    [nltk_data]    | Downloading package state_union to /root/nltk_data...
    [nltk_data]    |   Package state_union is already up-to-date!
    [nltk_data]    | Downloading package stopwords to /root/nltk_data...
    [nltk_data]    |   Package stopwords is already up-to-date!
    [nltk_data]    | Downloading package subjectivity to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package subjectivity is already up-to-date!
    [nltk_data]    | Downloading package swadesh to /root/nltk_data...
    [nltk_data]    |   Package swadesh is already up-to-date!
    [nltk_data]    | Downloading package switchboard to /root/nltk_data...
    [nltk_data]    |   Package switchboard is already up-to-date!
    [nltk_data]    | Downloading package timit to /root/nltk_data...
    [nltk_data]    |   Package timit is already up-to-date!
    [nltk_data]    | Downloading package toolbox to /root/nltk_data...
    [nltk_data]    |   Package toolbox is already up-to-date!
    [nltk_data]    | Downloading package treebank to /root/nltk_data...
    [nltk_data]    |   Package treebank is already up-to-date!
    [nltk_data]    | Downloading package twitter_samples to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package twitter_samples is already up-to-date!
    [nltk_data]    | Downloading package udhr to /root/nltk_data...
    [nltk_data]    |   Package udhr is already up-to-date!
    [nltk_data]    | Downloading package udhr2 to /root/nltk_data...
    [nltk_data]    |   Package udhr2 is already up-to-date!
    [nltk_data]    | Downloading package unicode_samples to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package unicode_samples is already up-to-date!
    [nltk_data]    | Downloading package universal_treebanks_v20 to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package universal_treebanks_v20 is already up-to-
    [nltk_data]    |       date!
    [nltk_data]    | Downloading package verbnet to /root/nltk_data...
    [nltk_data]    |   Package verbnet is already up-to-date!
    [nltk_data]    | Downloading package verbnet3 to /root/nltk_data...
    [nltk_data]    |   Package verbnet3 is already up-to-date!
    [nltk_data]    | Downloading package webtext to /root/nltk_data...
    [nltk_data]    |   Package webtext is already up-to-date!
    [nltk_data]    | Downloading package wordnet to /root/nltk_data...
    [nltk_data]    |   Package wordnet is already up-to-date!
    [nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...
    [nltk_data]    |   Package wordnet_ic is already up-to-date!
    [nltk_data]    | Downloading package words to /root/nltk_data...
    [nltk_data]    |   Package words is already up-to-date!
    [nltk_data]    | Downloading package ycoe to /root/nltk_data...
    [nltk_data]    |   Package ycoe is already up-to-date!
    [nltk_data]    | Downloading package rslp to /root/nltk_data...
    [nltk_data]    |   Package rslp is already up-to-date!
    [nltk_data]    | Downloading package maxent_treebank_pos_tagger to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package maxent_treebank_pos_tagger is already up-
    [nltk_data]    |       to-date!
    [nltk_data]    | Downloading package universal_tagset to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package universal_tagset is already up-to-date!
    [nltk_data]    | Downloading package maxent_ne_chunker to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package maxent_ne_chunker is already up-to-date!
    [nltk_data]    | Downloading package punkt to /root/nltk_data...
    [nltk_data]    |   Package punkt is already up-to-date!
    [nltk_data]    | Downloading package book_grammars to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package book_grammars is already up-to-date!
    [nltk_data]    | Downloading package sample_grammars to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package sample_grammars is already up-to-date!
    [nltk_data]    | Downloading package spanish_grammars to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package spanish_grammars is already up-to-date!
    [nltk_data]    | Downloading package basque_grammars to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package basque_grammars is already up-to-date!
    [nltk_data]    | Downloading package large_grammars to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package large_grammars is already up-to-date!
    [nltk_data]    | Downloading package tagsets to /root/nltk_data...
    [nltk_data]    |   Package tagsets is already up-to-date!
    [nltk_data]    | Downloading package snowball_data to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package snowball_data is already up-to-date!
    [nltk_data]    | Downloading package bllip_wsj_no_aux to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!
    [nltk_data]    | Downloading package word2vec_sample to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package word2vec_sample is already up-to-date!
    [nltk_data]    | Downloading package panlex_swadesh to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package panlex_swadesh is already up-to-date!
    [nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...
    [nltk_data]    |   Package mte_teip5 is already up-to-date!
    [nltk_data]    | Downloading package averaged_perceptron_tagger to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package averaged_perceptron_tagger is already up-
    [nltk_data]    |       to-date!
    [nltk_data]    | Downloading package averaged_perceptron_tagger_ru to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package averaged_perceptron_tagger_ru is already
    [nltk_data]    |       up-to-date!
    [nltk_data]    | Downloading package perluniprops to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package perluniprops is already up-to-date!
    [nltk_data]    | Downloading package nonbreaking_prefixes to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!
    [nltk_data]    | Downloading package vader_lexicon to
    [nltk_data]    |     /root/nltk_data...
    [nltk_data]    |   Package vader_lexicon is already up-to-date!
    [nltk_data]    | Downloading package porter_test to /root/nltk_data...
    [nltk_data]    |   Package porter_test is already up-to-date!
    [nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...
    [nltk_data]    |   Package wmt15_eval is already up-to-date!
    [nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...
    [nltk_data]    |   Package mwa_ppdb is already up-to-date!
    [nltk_data]    | 
    [nltk_data]  Done downloading collection all


    Collecting nltk
    [?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 3.4MB/s eta 0:00:01
    [?25hCollecting click (from nltk)
    [?25l  Downloading https://files.pythonhosted.org/packages/dd/c0/4d8f43a9b16e289f36478422031b8a63b54b6ac3b1ba605d602f10dd54d6/click-7.1.1-py2.py3-none-any.whl (82kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 834kB/s  eta 0:00:01
    [?25hCollecting joblib (from nltk)
    [?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 296kB 39.2MB/s eta 0:00:01
    [?25hCollecting regex (from nltk)
    [?25l  Downloading https://files.pythonhosted.org/packages/0f/fa/a9e3ad47c189969e3233031187b323fe20005fee4bfc8edcb24f8ffbe540/regex-2020.4.4-cp37-cp37m-manylinux2010_x86_64.whl (679kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 686kB 41.1MB/s eta 0:00:01
    [?25hRequirement already satisfied, skipping upgrade: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.32.1)
    Building wheels for collected packages: nltk
      Building wheel for nltk (setup.py) ... [?25ldone
    [?25h  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306
    Successfully built nltk
    Installing collected packages: click, joblib, regex, nltk
      Found existing installation: nltk 3.4.5
        Uninstalling nltk-3.4.5:
          Successfully uninstalled nltk-3.4.5
    Successfully installed click-7.1.1 joblib-0.14.1 nltk-3.5 regex-2020.4.4



```python
# Import stop words 
from nltk.corpus import stopwords 
from nltk.tokenize import word_tokenize 
stop_words = set(stopwords.words('english'))
print(type(stop_words))
```

    <class 'set'>


## Split into words and lower case for easier processing


```python

data2 = data.map(lambda x: x[47:400])
data2 = data2.flatMap(lambda x: x.split(','))
data2 = data2.flatMap(lambda x: x.split(' '))
data2 = data2.map(lambda x : x.lower())
data2.take(5)
```




    ['from', 'kplu:', 'why', 'most', 'people']



## Remove stop words


```python
# Remove the stop words given from nltk from the data 
data3 = data2.filter(lambda x: x not in stop_words)

# Remove some 'null' and '-' from the data as well.
extra_sw = {'null', '-', }
data3 = data3.filter(lambda x: x not in extra_sw)
data3.take(5)
```




    ['kplu:', 'people', 'get', 'divorced', 'march']



## Using nltk to tokenize text, then select only nouns


```python
def word_tokenize1(x):
    return nltk.word_tokenize(x)
words = data3.flatMap(word_tokenize1)
words.take(2)
```


    ---------------------------------------------------------------------------

    Py4JJavaError                             Traceback (most recent call last)

    <ipython-input-21-288d8e2818ae> in <module>
          2     return nltk.word_tokenize(x)
          3 words = data3.flatMap(word_tokenize1)
    ----> 4 words.take(2)
    

    /usr/lib/spark/python/pyspark/rdd.py in take(self, num)
       1356 
       1357             p = range(partsScanned, min(partsScanned + numPartsToTry, totalParts))
    -> 1358             res = self.context.runJob(self, takeUpToNumLeft, p)
       1359 
       1360             items += res


    /usr/lib/spark/python/pyspark/context.py in runJob(self, rdd, partitionFunc, partitions, allowLocal)
       1043         # SparkContext#runJob.
       1044         mappedRDD = rdd.mapPartitions(partitionFunc)
    -> 1045         sock_info = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)
       1046         return list(_load_from_socket(sock_info, mappedRDD._jrdd_deserializer))
       1047 


    /usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py in __call__(self, *args)
       1255         answer = self.gateway_client.send_command(command)
       1256         return_value = get_return_value(
    -> 1257             answer, self.gateway_client, self.target_id, self.name)
       1258 
       1259         for temp_arg in temp_args:


    /usr/lib/spark/python/pyspark/sql/utils.py in deco(*a, **kw)
         61     def deco(*a, **kw):
         62         try:
    ---> 63             return f(*a, **kw)
         64         except py4j.protocol.Py4JJavaError as e:
         65             s = e.java_exception.toString()


    /usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name)
        326                 raise Py4JJavaError(
        327                     "An error occurred while calling {0}{1}{2}.\n".
    --> 328                     format(target_id, ".", name), value)
        329             else:
        330                 raise Py4JError(


    Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
    : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23.0 (TID 43, will-bda-w-0.us-central1-a.c.genuine-habitat-264302.internal, executor 3): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py", line 240, in main
        func, profiler, deserializer, serializer = read_command(pickleSer, infile)
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py", line 60, in read_command
        command = serializer._read_with_length(file)
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 171, in _read_with_length
        return self.loads(obj)
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 566, in loads
        return pickle.loads(obj, encoding=encoding)
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/cloudpickle.py", line 929, in subimport
        __import__(name)
    ModuleNotFoundError: No module named 'nltk'
    
    	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:336)
    	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:475)
    	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:458)
    	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:290)
    	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
    	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
    	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
    	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
    	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
    	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
    	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
    	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
    	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
    	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
    	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
    	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
    	at org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:152)
    	at org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:152)
    	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)
    	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)
    	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
    	at org.apache.spark.scheduler.Task.run(Task.scala:109)
    	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
    	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    	at java.lang.Thread.run(Thread.java:748)
    
    Driver stacktrace:
    	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1661)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1649)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1648)
    	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
    	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
    	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1648)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
    	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831)
    	at scala.Option.foreach(Option.scala:257)
    	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1882)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1831)
    	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1820)
    	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
    	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)
    	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)
    	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:152)
    	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
    	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.lang.reflect.Method.invoke(Method.java:498)
    	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
    	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
    	at py4j.Gateway.invoke(Gateway.java:282)
    	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
    	at py4j.commands.CallCommand.execute(CallCommand.java:79)
    	at py4j.GatewayConnection.run(GatewayConnection.java:238)
    	at java.lang.Thread.run(Thread.java:748)
    Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py", line 240, in main
        func, profiler, deserializer, serializer = read_command(pickleSer, infile)
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py", line 60, in read_command
        command = serializer._read_with_length(file)
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 171, in _read_with_length
        return self.loads(obj)
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 566, in loads
        return pickle.loads(obj, encoding=encoding)
      File "/usr/lib/spark/python/lib/pyspark.zip/pyspark/cloudpickle.py", line 929, in subimport
        __import__(name)
    ModuleNotFoundError: No module named 'nltk'
    
    	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:336)
    	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:475)
    	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:458)
    	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:290)
    	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
    	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
    	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
    	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
    	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
    	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
    	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
    	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
    	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)
    	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
    	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)
    	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
    	at org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:152)
    	at org.apache.spark.api.python.PythonRDD$$anonfun$3.apply(PythonRDD.scala:152)
    	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)
    	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2074)
    	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
    	at org.apache.spark.scheduler.Task.run(Task.scala:109)
    	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345)
    	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
    	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
    	... 1 more




```python
# # Remove stop words
# stopW = words.filter(lambda word : word[0] not in stop_words and word[0] != '')
# # Remove punctuations 
# import string
# list_punct=list(string.punctuation)
# filtered_data = stopW.filter(lambda punct : punct not in list_punct)
# filtered_data.take(2)
```


```python
# def pos_tag(x):
#     return nltk.pos_tag([x])
# pos_word = filtered_data.map(pos_tag)
# nouns = [word for (word, pos) in pos_word if pos[0] == 'N']
```

## Alternative method

### Convert to strings instead


```python
x = data3.collect()
print(len(x))
```

    10496823



```python
# Convert to strings
str1 = ' '.join(str(e) for e in x[0:int(len(x)/2)])
str2 = ' '.join(str(e) for e in x[int(len(x)/2):])
x = ['']
# print(str1)
```

### Perform some data cleaning. Remove numbers, punctuations, convert to lower case and remove excessive whitespaces.


```python
# Clean up the data some more.
import re
import string
def clean_text(text):
    # Remove numbers
    text_nonum = re.sub(r'\d+', '', text)
    # Remove punctuations and convert characters to lower case
    text_nopunct = "".join([char.lower() for char in text_nonum if char not in string.punctuation]) 
    # Substitute multiple whitespace with single whitespace
    # Also, removes leading and trailing whitespaces
    text_no_doublespace = re.sub('\s+', ' ', text_nopunct).strip()
    return text_no_doublespace
str1 = clean_text(str1)
str2 = clean_text(str2)
# print(str1)

```

### Tokenize words with NLTK, check tags for nouns and save only nouns


```python
# Using nltk, tokenize words and then using tags to check for nouns
# Split into 4 parts to prevent memory error
a = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(str1[:int(len(str1)/2)])) if pos[0] == 'N']
b = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(str1[int(len(str1)/2):])) if pos[0] == 'N']
c = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(str1[:int(len(str2)/2)])) if pos[0] == 'N']
d = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(str1[int(len(str2)/2):])) if pos[0] == 'N']
print(a[:50])
str1 = ''
str2 = ''
```

    ['kplu', 'people', 'march', 'divorce', 'business', 'time', 'year', 'business', 'looks', 'reasons', 'filings', 'march', 'year', 'kpluorg', 'httpwwwkpluorgpostwhymostpeoplegetdivorcedmarch', 'horse', 'london', 'olympics', 'fedex', 'athletes', 'summers', 'games', 'gymnasts', 'wrestlers', 'horses', 'dressage', 'events', 'man', 'job', 'horses', 'feat', 'scenes', 'stories', 'photos', 'â€”', 'beautiful', 'â€”', 'captions', 'guess', 'beautiful', 'thats', 'chalmers', 'thats', 'experience', 'link', 'sharedstory', 'future', 'journalism', 'remake', 'tale']


### Merge all the lists together and then convert to RDD.


```python
# Combine the lists together again
a += b + c + d
```


```python
# Convert it into RDD 
data3 = sc.parallelize(list(a))
data3.take(2)
```




    ['kplu', 'people']



## Find most frequently used nouns


```python
# Count occurences of words and find most frequently used nouns
data3 = data3.map(lambda x : (x,1))
from operator import add
data3 = data3.reduceByKey(add)
data3 = data3.map(lambda x: (x[1], x[0]))
data3 = data3.sortByKey(ascending=False)
data3.take(20)
```




    [(66424, 'sharedstory'),
     (55786, 'link'),
     (28074, 'video'),
     (24622, 'news'),
     (23362, 'people'),
     (22858, 'photo'),
     (22046, 'photos'),
     (19954, 'years'),
     (19778, 'police'),
     (19538, 'addedphotos'),
     (17138, 'president'),
     (17086, 'addedvideo'),
     (16528, 'timeline'),
     (16282, 'man'),
     (16140, 'trump'),
     (14928, 'world'),
     (14724, 'abcnewsgocom'),
     (14172, 'time'),
     (14072, 'cbsnws'),
     (13762, 'cnncom')]



# Summary 
<blockquote>
From the results given above, we can see the most frequently used nouns. Although, words such as 'sharedstory', 'link', 'video', etc are less meaningful because they are found in almost every post. They are simply words that are used in facebook posts to determiine the type or parts of a post.
<br> 
Looking more into the list, we see 'police', 'president', 'man', and 'trump' appear very frequently. This gives us an impression of what kind of posts are common. These posts are most likely related to politics and the U.S to be more exact.


</blockquote>


```python

```
